/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

syntax = "proto2";

package tflite.task.vision;

import "tensorflow/lite/experimental/acceleration/configuration/configuration.proto";
import "tensorflow_lite_support/cc/task/core/proto/external_file.proto";

// Options for setting up an ImageSegmenter.
// Next Id: 8
message ImageSegmenterOptions {
  // The external model file, as a single standalone TFLite file. If it is
  // packed with TFLite Model Metadata [1], those are used to populate label
  // map. Models without any such metadata or partial metadata are supported,
  // but may result in the segmenter providing degraded functionality;
  // typically, a model that doesn't contain any label map won't be able to
  // return any class or display names.
  //
  // [1]: https://www.tensorflow.org/lite/convert/metadata
  optional core.ExternalFile model_file_with_metadata = 5;

  // The locale to use for display names specified through the TFLite Model
  // Metadata, if any. Defaults to English.
  optional string display_names_locale = 6 [default = "en"];

  // Output mask type. This allows specifying the type of post-processing to
  // perform on the raw model results (see SegmentationResult proto for more).
  enum OutputType {
    UNSPECIFIED = 0;
    // Gives a single output mask where each pixel represents the class which
    // the pixel in the original image was predicted to belong to.
    CATEGORY_MASK = 1;
    // Gives a list of output masks where, for each mask, each pixel represents
    // the prediction confidence, usually in the [0, 1] range.
    CONFIDENCE_MASK = 2;
  }
  // Optional output mask type.
  optional OutputType output_type = 3 [default = CATEGORY_MASK];

  // The number of threads to be used for TFLite ops that support
  // multi-threading when running inference with CPU.
  // num_threads should be greater than 0 or equal to -1. Setting num_threads to
  // -1 has the effect to let TFLite runtime set the value.
  optional int32 num_threads = 7 [default = -1];

  // Advanced settings specifying how to accelerate the model inference using
  // dedicated delegates.
  // Only NONE, GPU, NNAPI and HEXAGON delegates are supported for now;
  // specifying another delegate will cause an UnimplementedError to be thrown
  // at initialization time.
  //
  // IMPORTANT: in order to use a delegate, the appropriate delegate plugin
  // needs to be linked at build time. See comment above the "image_segmenter"
  // target at:
  // https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/cc/task/vision/BUILD
  //
  // See settings definition at:
  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/acceleration/configuration/configuration.proto
  optional tflite.proto.ComputeSettings compute_settings = 4;

  // Reserved tags.
  reserved 1, 2;
}
